{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "from utils import complete_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tokenizer is the object that separate text into tokens.\n",
    "\n",
    "Tokens are \"units\" of text: they can be single caracters or multiple words.\n",
    "\n",
    "There is a fixed set of tokens that is called the vocabulary.\n",
    "\n",
    "The vocabulary is computed automatically based on the text we used for training the Language model\n",
    "\n",
    "Here, we compute a vocabulary with 5000 tokens using the text from Wikipedia in Khmer (can take a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plain_wikipedia_file = 'plain_wikipedia.txt'\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=5000)\n",
    "tokenizer.train(files=[plain_wikipedia_file], trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use the encode method of the tokenizer to split the text \"ប្រាសាទ អង្គរវត្ត\" into tokens.\n",
    "\n",
    "As you can see, tokens are not necessarly words, they can be single characters. If you want to know more about how the vocabulary of token is computed you can have a look here: [https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3632, 4960, 1138, 3391]\n",
      "['ប្រាសាទ', ' អង្គ', 'រ', 'វត្ត']\n"
     ]
    }
   ],
   "source": [
    "text = \"ប្រាសាទ អង្គរវត្ត\"\n",
    "output = tokenizer.encode(text)\n",
    "print(output.ids)\n",
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a sequence of ids, we can build back the sentence using the decode method of the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ប្រាសាទ  អង្គ រ វត្ត\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output.ids, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: as you can see, the decoder did not output the exact same sequence that we inputed: \n",
    "\n",
    "Input: \"ប្រាសាទ អង្គរវត្ត\"\n",
    "\n",
    "Output: \"ប្រាសាទ អង្គ រ វត្ត\"\n",
    "\n",
    "The reason is that the Tokenizer we used is not adapted to the Khmer language.\n",
    "\n",
    "In the future, if you want to develop a languge model for Khmer, you will need to develop you own tokenizer that takes into account the specificity of the language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are loading a generative language model for khmer that we already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = GPT2LMHeadModel.from_pretrained(\"gpt2-wikipedia-khmer-no-pretrain\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-wikipedia-khmer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of a generative language model (other names include autoregressive language model or causal language model) as a very advanced algorithms for autocomplete:\n",
    "\n",
    "It takes as input a piece of text and will complete it until a stop token is gneerated or the max length is reached. \n",
    "\n",
    "The model is probabilistic: based on the text that we used to train it, it will output the most porbably sequence of token that should follow the input piece of text.\n",
    "\n",
    "It does NOT use facts from a Knoweldge Base. \n",
    "\n",
    "Never trust the output from a generative language model: it generates probable text NOT factual text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training\n",
      "-5.8727145 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 យក យក យក យក យក យក យក យក យក 朝 ្អូន ្អូន ្អូន\n",
      "-5.8830476 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 យក យក យក យក យក យក យក យក យក យក យក យក យក\n",
      "-5.8839407 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪\n",
      "-5.8843255 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 យក យក យក យក យក យក យក យក យក យក ң ң ң\n",
      "-5.887452 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 យក យក យក យក យក យក យក យក យក ң ң ң ң\n",
      "-5.887632 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 យក យក យក យក យក យក យក យក យក យក យក ң ң\n",
      "-5.8886433 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 ң ң ң ң ң ң ң ң ң ң ң\n",
      "-5.889457 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 ң ң ң ң ң ң ң ң ң ң ң ң\n",
      "-5.8896036 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪\n",
      "-5.891625 ប្រាសាទ  អង្គ រ វត្ត គ្រូ 別 別 別 別 別 別 別 別 別 別 ˧ ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 ˧ ˧ ˧ ˧ ˧ ˧ ˧ 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 阪 យក យក យក យក យក យក យក យក យក 朝 ្អូន ្អូន ຄ\n",
      "After training\n",
      "-0.44227907 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ១៦ ០ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ ១\n",
      "-0.45064276 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ០០ ២ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ ១\n",
      "-0.45441994 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១៣ ៤ ០ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ ១\n",
      "-0.45484048 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ ១\n",
      "-0.45624918 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ១៦ ៥ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ ១\n",
      "-0.4587316 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ១៦ ៥ )  ក្រោយ ធ្វើ ពិធី រាជា ភិ សេ ក គ្រ ង\n",
      "-0.4687758 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ១៦ ០ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ\n",
      "-0.47027704 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ៧ ២ - ១៣ ៤ ០ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង\n",
      "-0.47908634 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១៣ ៤ ០ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ\n",
      "-0.47942066 ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I I )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១ ០០ ២ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ៣ ០ - ១ ១៦ ០ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ ការណ៍ ក្នុង ឆ្នាំ \n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"ប្រាសាទ អង្គរវត្ត\"\n",
    "print(\"Before training\")\n",
    "complete_text(sentence_to_complete, initial_model, tokenizer)\n",
    "print(\"After training\")\n",
    "complete_text(sentence_to_complete, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3973586 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។\n",
      "-0.41015318 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ ក្នុង\n",
      "-0.41032267 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ  ។\n",
      "-0.41949642 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ នូវ\n",
      "-0.4245352 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ  ក្នុង\n",
      "-0.42643344 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ នៃ\n",
      "-0.42781493 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ល ឹក\n",
      "-0.42964873 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ  \n",
      "-0.4309536 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ អំពី\n",
      "-0.43109456 ជំ រាប សួរ  ខ្ញុំ ព្រះករុណ ា  សូម សម ាទ ាន នូវ សិ ក្ខ ាបទ  គឺ ច េត នា ជា ហេតុ វ ៀរ ចាក ហេតុ ជា ទីតាំង នៃ សេចក្តី ប្រ ម ាទ  គឺ ផ ឹក នូវ ទឹក ស្រ វ ឹង  គឺ សុ រ ានិ ង ម េរ ័យ ។ ស្ វា ធ្យ ាយ របស់\n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"ជំរាបសួរ ខ្ញុំ\"\n",
    "complete_text(sentence_to_complete, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4562883 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។\n",
      "-0.4602402 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។\n",
      "-0.4920465 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ​\n",
      "-0.51525223 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ពី\n",
      "-0.5208448 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ពី\n",
      "-0.52344555 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ រ\n",
      "-0.527477 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ មាន\n",
      "-0.52816623 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា  ជា តំណ ាង នៃ ព្រះរាជា ណាចក្រ កម្ពុជា\n",
      "-0.53075206 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ មាន\n",
      "-0.5331759 ហ៊ុន  ស ែន ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ជាន ាយ ក រដ្ឋ មន ្រ្ត ី នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ មុខ\n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"ហ៊ុន សែន\"\n",
    "complete_text(sentence_to_complete, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.51246643 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។\n",
      "-0.5470465 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ -\n",
      "-0.5515927 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ -\n",
      "-0.5562063 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ -\n",
      "-0.56327087 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ ថ\n",
      "-0.56541455 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ -\n",
      "-0.5659427 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ -\n",
      "-0.5671319 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ រដ្ឋ\n",
      "-0.5701202 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ រដ្ឋ\n",
      "-0.5708964 ប៊ ុន រ៉ ាន ី ន ត ុន រដ្ឋ មន្ត្រី ក្រស ួង យុ ត្តិ ធម៌ នៃ ព្រះរាជា ណាចក្រ កម្ពុជា ។ -\n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"ប៊ុនរ៉ានី\"\n",
    "complete_text(sentence_to_complete, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4089401 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ធ .\n",
      "-0.41584086 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ជា .  ទ ស ក . ខ ុ .  ធ .\n",
      "-0.4190509 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ខ ុ .  ធ .\n",
      "-0.4313643 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ខ ុ .  ធ .\n",
      "-0.43306038 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ .\n",
      "-0.43394488 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ធ .\n",
      "-0.43467146 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ខ ុ .  ធ\n",
      "-0.4390796 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ធ . , \n",
      "-0.44117218 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ធ . ខ ុ .  ធ .  ជា . \n",
      "-0.4443256 ត ើ  1 + 1  ជា អ្វី ? ខ ុ .  ធ . ) ខ ុ .  ធ . ,  ខ ុ .  ធ . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ជា .  ទ ស ក . ,  ខ ុ .  ជា .  ទ\n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"តើ 1+1 ជាអ្វី?\"\n",
    "complete_text(sentence_to_complete, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-khmer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
