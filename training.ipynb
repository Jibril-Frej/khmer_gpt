{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from transformers import AdamW, GPT2Config, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_wikipedia_file = 'text/AA/wiki_00' \n",
    "plain_wikipedia_file = 'plain_wikipedia.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the json file and write the article title and text into a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(plain_wikipedia_file, 'w') as f:\n",
    "    for line in open(json_wikipedia_file, 'r', encoding='utf-8'):\n",
    "        article = json.loads(line)\n",
    "        f.write(article['title'])\n",
    "        f.write('\\n')\n",
    "        f.write(article['text'])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Tokenizer: it is the object that will analyse all the text and build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the text using the tikenizer to get the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train(files=[plain_wikipedia_file], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3632, 4960, 1138, 3391]\n",
      "['ប្រាសាទ', ' អង្គ', 'រ', 'វត្ត']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ប្រាសាទ អង្គរវត្ត\"\n",
    "\n",
    "output = tokenizer.encode(sentence)\n",
    "print(output.ids)\n",
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ប្រាសាទ  អង្គ រ វត្ត\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output.ids, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "batch_size = 32\n",
    "padding_value = tokenizer.token_to_id(\"[PAD]\")\n",
    "n_layer=4\n",
    "n_head=4\n",
    "n_embed=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170392it [00:10, 15944.27it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "with open(plain_wikipedia_file, 'r', encoding='utf-8') as file:\n",
    "    for line in tqdm(file):\n",
    "        tokenized_line = tokenizer.encode(line.strip()).ids\n",
    "        if tokenized_line:\n",
    "            tokenized_texts.append(tokenized_line[:max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tokenized_texts[idx])\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # Pad the sequences in the batch\n",
    "    batch_padded = pad_sequence([sequence for sequence in batch], \n",
    "                                batch_first=True, padding_value=padding_value)\n",
    "    # Create attention masks\n",
    "    attention_masks = torch.zeros(batch_padded.shape, dtype=torch.long)\n",
    "    attention_masks[batch_padded != padding_value] = 1\n",
    "\n",
    "    return batch_padded, attention_masks\n",
    "\n",
    "\n",
    "dataset = TextDataset(tokenized_texts)\n",
    "data_loader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size = len(tokenizer.get_vocab()), \n",
    "    n_positions = max_length, \n",
    "    n_layer = n_layer, \n",
    "    n_head = n_head, \n",
    "    n_embed = n_embed, \n",
    "    pad_token_id = padding_value)\n",
    "model = GPT2LMHeadModel(config)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"gpt2-wikipedia-khmer-no-pretrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត េយ្យ េយ្យ េយ្យ េយ្យ េយ្យ េយ្យ េយ្យ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ ប្តូរ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ និ\n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"ប្រាសាទ អង្គរវត្ត\"\n",
    "input_text = sentence_to_complete\n",
    "input_ids = torch.tensor([tokenizer.encode(input_text).ids]).to(device)\n",
    "attention_mask = torch.ones_like(input_ids).to(device)\n",
    "model.eval()\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    attention_mask=attention_mask, \n",
    "    max_length=max_length, \n",
    "    num_beams=1, \n",
    "    num_return_sequences=1\n",
    "    ).to(device)\n",
    "for prediction in output:\n",
    "    predicted_text = tokenizer.decode(prediction.tolist(), skip_special_tokens=True)\n",
    "    print(\"Predicted text:\", predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0/25940, Loss: 8.236664772033691\n",
      "Epoch: 0, Batch: 1000/25940, Loss: 2.305311679840088\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត\n",
      "Epoch: 1, Batch: 2000/25940, Loss: 2.2689266204833984\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត\n",
      "Epoch: 2, Batch: 3000/25940, Loss: 2.1256203651428223\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត\n",
      "Epoch: 3, Batch: 4000/25940, Loss: 1.6820898056030273\n",
      "Epoch: 3, Batch: 5000/25940, Loss: 1.8167405128479004\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត\n",
      "Epoch: 4, Batch: 6000/25940, Loss: 1.7585417032241821\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ប្រាសាទ ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ ព្រះ វិហារ វត្ត ព្រះ វិហារ វត្ត ព្រះ វិហារ ព្រះ វិហារ វត្ត ព្រះ\n",
      "Epoch: 5, Batch: 7000/25940, Loss: 1.5956480503082275\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ប្រាសាទ ព្រះ វិហារ ព្រះ ព្រះ វិហារ ព្រះ ព្រះ វិហារ ព្រះ ព្រះ វិហារ ព្រះ ព្រះ វិហារ ព្រះ ព្រះ វិហារ ។ ប្រាសាទ ព្រះ វិហារ វត្ត ព្រះ ធាតុ ថ្ម បាយ ក្រ ៀម មាន ទីតាំង ស្ថិតនៅក្នុង ភូមិ ស្រ ព ាំង ប្រាសាទ  ស្រុក ព្រះ វិហារ ។  ប្រាសាទ នេះ កសាង ឡើង ក្នុង ពុទ្ធ ស ក រាជ  ២ ៤ ៤\n",
      "Epoch: 6, Batch: 8000/25940, Loss: 1.9235883951187134\n",
      "Epoch: 6, Batch: 9000/25940, Loss: 1.5817996263504028\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ប្រាសាទ ព្រះ វិហារ ព្រះ កែវ ម រក ត ក្នុង រ ចន ាប ថ ព្រះ វិហារ ក្នុង រ ចន ាប ថ ព្រះ វិហារ បុរាណ  ស ាង សង់ ឡើង ក្នុង រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( គ.ស  ១ ៥ ១៦ - ១ ១៦ ០ )  ប្រាសាទ នេះ កសាង អំពី ឥ ដ្ឋ នៅ ប្រាសាទ\n",
      "Epoch: 7, Batch: 10000/25940, Loss: 1.6490087509155273\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ប្រាសាទ ព្រះ វិហារ វត្ត ព្រះ ធាតុ ថ្ម ដ ា មាន ទីតាំង ស្ថិតនៅក្នុង ភូមិ ស ំប ូរ  ឃុំ ស ំប ូរ  ស្រុក ប្រាសាទ ស ំប ូរ  ខេត្ត កំពង់ ធំ ។  ប្រាសាទ នេះ ត្រូវបាន កសាង ឡើង ក្នុង សម័យ ច េន ឡ ា  ដោយ ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ដើម្បី ឧ ទ្ ទិស ដល់ ព្រាហ្មណ៍\n",
      "Epoch: 8, Batch: 11000/25940, Loss: 1.3772234916687012\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត\n",
      "Epoch: 9, Batch: 12000/25940, Loss: 1.5532900094985962\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ឥ ដ្ឋ ឥ ដ្ឋ ឥ ដ្ឋ ពល ឥ ដ្ឋ ឥ ដ្ឋ ពល ឥ ដ្ឋ ពល ឥ ដ្ឋ ពល ពល ឥ ដ្ឋ ពល ពល ព ាហ នៈ ជា ឥ ដ្ឋ ពល ពល ព ាហ នៈ ។\n",
      "Epoch: 10, Batch: 13000/25940, Loss: 1.486263632774353\n",
      "Epoch: 10, Batch: 14000/25940, Loss: 1.5283211469650269\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ប្រាសាទ ព្រះ ខ ័ន ព្រៃ នគរ ក្នុង ភូមិ ប ត់ ព្រះ ន ង្គ ័ ល ក្នុង ភូមិ ហ េ ម ពាន ្ត ឃុំ ប្រាសាទ បា គ ង  ស្រុក ប្រាសាទ បា គ ង  ខេត្ត សៀម រាប ។  ប្រាសាទ នេះ កសាង ឡើង ក្នុង សម័យ ច េន ឡ ា  ដោយ ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ដើម្បី ឧ ទ្\n",
      "Epoch: 11, Batch: 15000/25940, Loss: 1.5130820274353027\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ប្រាសាទ ព្រះ វិហារ វត្ត ព្រះ កែវ ម រក ត  ដែលមាន ទីតាំង ស្ថិត ក្នុង ភូមិ ស្វាយ ជ្រ ុំ  ឃុំ ស្វាយ ជ្រ ុំ  ស្រុក ស្វាយ ជ្រ ំ  ខេត្ត ស្វាយ រ ៀង  មាន  ភូមិ ស្វាយ ជ្រ ំ  ឃុំ ស្វាយ ទ ាប  ស្រុក ស្វាយ ជ្រ ំ  ខេត្ត ស្វាយ រ ៀង  មាន  ភូមិ ÷\n",
      "Epoch: 12, Batch: 16000/25940, Loss: 1.5120575428009033\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ខ ិត ខំ ប្រ ឹង ប្រ ែង ដើម្បី ការពារ ប្រាសាទ ព្រះ វិហារ ។\n",
      "Epoch: 13, Batch: 17000/25940, Loss: 1.5012277364730835\n",
      "Epoch: 13, Batch: 18000/25940, Loss: 1.4310061931610107\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ខ ិត ខំ ប្រ ឹង ប្រ ែង ដើម្បី ការពារ ផល ប្រយោជន៍ ជាតិ ។\n",
      "Epoch: 14, Batch: 19000/25940, Loss: 1.489122748374939\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត\n",
      "Epoch: 15, Batch: 20000/25940, Loss: 1.3960248231887817\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត ខ ឿន ថ្ម បាយ ក្រ ៀម  និង  ថ្ម បាយ ក្រ ៀម ។  ប្រាសាទ នេះ ត្រូវបាន កសាង ឡើង ក្នុង រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ដើម្បី ឧ ទ្ ទិស ដល់ ព្រាហ្មណ៍ សាសនា ។\n",
      "Epoch: 16, Batch: 21000/25940, Loss: 1.2938389778137207\n",
      "Epoch: 16, Batch: 22000/25940, Loss: 1.0481200218200684\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត  ស ិ រី សុ គ ន្ធ ា  ក្នុង ឆ្នាំ ២០០ ៩   -  ១ ៩ ៩ ៦   -  ១ ៩ ៩ ៦ ) ,  ប្រាសាទ នេះ ត្រូវបាន កសាង ឡើង ក្នុង រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ក្នុង រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( ១ ១០ -\n",
      "Epoch: 17, Batch: 23000/25940, Loss: 1.3061386346817017\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  B or om   R e a ch e a  I )  or  ( A n g  Ch e y  Ch e y  Ch e y  Ch e y  Ch e y  Ch e y )  or  ( A n g  Ch e y  Ch e y  R o\n",
      "Epoch: 18, Batch: 24000/25940, Loss: 1.35853111743927\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត វ ន កម្ម ក្នុង រ ជ្ជ កាល ព្រះបាទ សូរ ្យ វរ្ម័ន ទី១  ( គ.ស  ១ ០០ ២ - ១០ ៥០ ) . វ . ទី១ ២ ) នៃ គ.ស  ព្រះ បាទ សូរ ្យ វរ្ម័ន ទី២  ( ១ ០០ ២ - ១០ ៥០ )\n",
      "Epoch: 19, Batch: 25000/25940, Loss: 1.339465856552124\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត  ( អង់គ្លេស :  S re i   D a v ar m an  I I )  or  ( A n g k or  W r ig h t  S e a )  មាន ត ួ ប៉ ម ចំនួន   3  ដែល ស្ថិតនៅ លើ កំព ូល ភ្នំ   នោះ មាន   ផ្ កាយ\n"
     ]
    }
   ],
   "source": [
    "batch_id = 0\n",
    "max_epoch = 20\n",
    "for epoch in range(max_epoch):\n",
    "    model.train()\n",
    "    for batch, attention_mask in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_id % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_id}/{len(data_loader)*max_epoch}, Loss: {loss.item()}')\n",
    "        batch_id += 1\n",
    "        # if batch_id % 500 == 0:\n",
    "        #     break\n",
    "    model.eval()\n",
    "    sentence_to_complete = \"ប្រាសាទ អង្គរវត្ត\"\n",
    "    input_text = sentence_to_complete\n",
    "    input_ids = torch.tensor([tokenizer.encode(input_text).ids]).to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        attention_mask = attention_mask, \n",
    "        max_length = max_length, \n",
    "        num_beams = 1, \n",
    "        num_return_sequences = 1).to(device)\n",
    "    for prediction in output:\n",
    "        predicted_text = tokenizer.decode(prediction.tolist(), skip_special_tokens=True)\n",
    "        print(\"Predicted text:\", predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"gpt2-wikipedia-khmer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-wikipedia-khmer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = json.load(open('outputs.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  រ ជ្ជ កាល គ្រ ង រាជ\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ នៅ\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ បន្ត\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ក្នុង\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ លើក\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ  ក្នុង\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ មក\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៣ - ១ ០០ ១ - ១ ០០ ១ - ១០ ៥០ )  ក្រោយ គ្រ ង\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ២ - ១០ ៥០ )  ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( គ.ស  ១ ០០ ១ -\n",
      "Predicted text: ប្រាសាទ  អង្គ រ វត្ត រ ជ្ជ កាល ព្រះបាទ ជ័យ វរ្ម័ន ទី ៧  ( សំ ស្ ក្រ ឹត )  ( ប្រ .ស | គ.ស   ០០ ០០ - ១០ ៥០ )  រ ជ្ជ កាល គ្រ ង រាជ  ( គ.ស  ១ ០០ ៦ - ១ ០០ ១ - ១ ០០ ១ )  ក្រោយ គ្រ ង រាជ សម្បត្តិ ផ្លូវ\n"
     ]
    }
   ],
   "source": [
    "sentence_to_complete = \"ប្រាសាទ អង្គរវត្ត\"\n",
    "input_text = sentence_to_complete\n",
    "input_ids = torch.tensor([tokenizer.encode(input_text).ids])\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "model.train()\n",
    "output = model.generate(\n",
    "    input_ids, \n",
    "    attention_mask=attention_mask, \n",
    "    max_length=64, \n",
    "    num_beams=10,\n",
    "    num_return_sequences=10\n",
    "    )\n",
    "for prediction in output:\n",
    "    predicted_text = tokenizer.decode(prediction.tolist(), skip_special_tokens=True)\n",
    "    print(\"Predicted text:\", predicted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-khmer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
